Directory tree, stemming from root "/home/caleb/repo/cosm-c360-tools":
├── README.md (169 lines)
├── TESTING.md (63)
├── cosmos.py (92)
├── dev.md (349)
├── pyproject.toml (11)
├── src (1230)
│   └── cosmos (1230)
│       │   ├── __init__.py (1)
│       │   ├── cli.py (176)
│       │   ├── manifest.py (204)
│       │   ├── preflight.py (197)
│       │   ├── processor.py (280)
│       │   ├── utils.py (94)
│       │   └── validation.py (278)
└── tests (550)
    │   ├── __init__.py (1)
    │   ├── test_data (0)
    │   ├── test_integration.py (20)
    │   ├── test_manifest.py (117)
    │   ├── test_processing.py (214)
    │   └── test_validation.py (198)
----
----
Full Path: cosmos.py

# File: cosmos.py

import sys
from pathlib import Path

from src.cosmos.cli import run_cli
from src.cosmos.preflight import run_self_test
from src.cosmos.utils import print_info, print_error, print_success
from src.cosmos.manifest import find_manifest, ManifestParser
from src.cosmos.validation import InputValidator
from src.cosmos.processor import VideoProcessor, ProcessingOptions, ProcessingMode

def main():
    config = run_cli()

    input_dir = Path(config["input_dir"])
    output_dir = Path(config["output_dir"])
    job_name = config.get("job_name", "default_job")

    # If self-test requested, run it and exit
    if config.get("self_test", False):
        manifest_path = Path(config["manifest"]) if "manifest" in config else None
        success = run_self_test(input_dir, output_dir, manifest_path)
        if success:
            print_success("Self-test passed. System ready.")
        else:
            print_error("Self-test failed. Please address the above issues.")
            sys.exit(1)
        sys.exit(0)

    # Attempt to find or load manifest
    manifest_path = config.get("manifest")
    if manifest_path:
        manifest_path = Path(manifest_path)
        # We'll trust the user on correctness. If invalid, validation will fail later.
        if not manifest_path.is_file():
            print_error(f"Specified manifest {manifest_path} not found.")
            sys.exit(1)
    else:
        # No manifest specified, try to find it automatically
        try:
            manifest_path = find_manifest(input_dir)
            if manifest_path is None:
                print_error("No manifest found. Please provide --manifest.")
                sys.exit(1)
        except ValueError as e:
            # Multiple manifests found
            print_error(str(e))
            print_error("Use --manifest to specify which manifest to use.")
            sys.exit(1)

    manifest_parser = ManifestParser(manifest_path)

    # Validate input directory and system readiness for actual processing
    validator = InputValidator(input_dir, output_dir, manifest_parser)
    validation_result = validator.validate_all()
    if not validation_result.can_proceed:
        print_error("Validation failed. Cannot proceed with processing.")
        for issue in validation_result.system_issues:
            print_error(f"System Issue: {issue.message}")
        sys.exit(1)

    # At this point, we have validated data and system. Proceed with processing.
    options = ProcessingOptions(
        output_resolution=(3840, 2160),
        quality_mode=ProcessingMode.BALANCED
    )
    processor = VideoProcessor(output_dir, options)

    # Process each valid clip
    for clip_name, clip_result in validation_result.clip_results.items():
        if clip_result.is_valid:
            result = processor.process_clip(clip_result)
            if result.success:
                print_success(f"Processed clip: {clip_name}. Output: {result.output_path}")
            else:
                print_error(f"Failed to process clip {clip_name}: {result.error}")

    # Write job info
    job_info_path = output_dir / "job_info.txt"
    with open(job_info_path, "w", encoding='utf-8') as f:
        f.write(f"Job Name: {job_name}\n")
        f.write(f"Input Directory: {input_dir}\n")
        f.write(f"Output Directory: {output_dir}\n")
        f.write(f"Manifest: {manifest_path}\n")
        f.write("Processing complete.\n")

    print_info("All done.")

if __name__ == "__main__":
    main()


----
Full Path: dev.md

# input directory structure/example metadata
a structured directory of .ts files (for data produced by a rather exotic ultra-high resolution camera, which saves four separate streams per file, and in approximately 1/10second chunks. 

You can get a good sense of the directory structure of the input data, and the two types of metadata available (a single clip manifest .xml, and meta.json files for each second) here:
```
Directory tree, stemming from root "/home/caleb/ladybird_failed_copy":
├── 0H (321 lines)
│   ├── 0M (180)
│   │   ├── 0S (3)
│   │   │   └── meta.json (3)
│   │   ├── 10S (3)
│   │   │   └── meta.json (3)
│   │   ├── 11S (3)
│   │   │   └── meta.json (3)
│   │   ├── 12S (3)
│   │   │   └── meta.json (3)
│   │   ├── 13S (3)
│   │   │   └── meta.json (3)
│   │   ├── 14S (3)
│   │   │   └── meta.json (3)
│   │   ├── 15S (3)
│   │   │   └── meta.json (3)
│   │   ├── 16S (3)
│   │   │   └── meta.json (3)
│   │   ├── 17S (3)
│   │   │   └── meta.json (3)
│   │   ├── 18S (3)
│   │   │   └── meta.json (3)
│   │   ├── 19S (3)
│   │   │   └── meta.json (3)
│   │   ├── 1S (3)
│   │   │   └── meta.json (3)
│   │   ├── 20S (3)
│   │   │   └── meta.json (3)
│   │   ├── 21S (3)
│   │   │   └── meta.json (3)
│   │   ├── 22S (3)
│   │   │   └── meta.json (3)
│   │   ├── 23S (3)
│   │   │   └── meta.json (3)
│   │   ├── 24S (3)
│   │   │   └── meta.json (3)
│   │   ├── 25S (3)
│   │   │   └── meta.json (3)
│   │   ├── 26S (3)
│   │   │   └── meta.json (3)
│   │   ├── 27S (3)
│   │   │   └── meta.json (3)
│   │   ├── 28S (3)
│   │   │   └── meta.json (3)
│   │   ├── 29S (3)
│   │   │   └── meta.json (3)
│   │   ├── 2S (3)
│   │   │   └── meta.json (3)
│   │   ├── 30S (3)
│   │   │   └── meta.json (3)
│   │   ├── 31S (3)
│   │   │   └── meta.json (3)
│   │   ├── 32S (3)
│   │   │   └── meta.json (3)
│   │   ├── 33S (3)
│   │   │   └── meta.json (3)
│   │   ├── 34S (3)
│   │   │   └── meta.json (3)
│   │   ├── 35S (3)
│   │   │   └── meta.json (3)
│   │   ├── 36S (3)
│   │   │   └── meta.json (3)
│   │   ├── 37S (3)
│   │   │   └── meta.json (3)
│   │   ├── 38S (3)
│   │   │   └── meta.json (3)
│   │   ├── 39S (3)
│   │   │   └── meta.json (3)
│   │   ├── 3S (3)
│   │   │   └── meta.json (3)
│   │   ├── 40S (3)
│   │   │   └── meta.json (3)
│   │   ├── 41S (3)
│   │   │   └── meta.json (3)
│   │   ├── 42S (3)
│   │   │   └── meta.json (3)
│   │   ├── 43S (3)
│   │   │   └── meta.json (3)
│   │   ├── 44S (3)
│   │   │   └── meta.json (3)
│   │   ├── 45S (3)
│   │   │   └── meta.json (3)
│   │   ├── 46S (3)
│   │   │   └── meta.json (3)
│   │   ├── 47S (3)
│   │   │   └── meta.json (3)
│   │   ├── 48S (3)
│   │   │   └── meta.json (3)
│   │   ├── 49S (3)
│   │   │   └── meta.json (3)
│   │   ├── 4S (3)
│   │   │   └── meta.json (3)
│   │   ├── 50S (3)
│   │   │   └── meta.json (3)
│   │   ├── 51S (3)
│   │   │   └── meta.json (3)
│   │   ├── 52S (3)
│   │   │   └── meta.json (3)
│   │   ├── 53S (3)
│   │   │   └── meta.json (3)
│   │   ├── 54S (3)
│   │   │   └── meta.json (3)
│   │   ├── 55S (3)
│   │   │   └── meta.json (3)
│   │   ├── 56S (3)
│   │   │   └── meta.json (3)
│   │   ├── 57S (3)
│   │   │   └── meta.json (3)
│   │   ├── 58S (3)
│   │   │   └── meta.json (3)
│   │   ├── 59S (3)
│   │   │   └── meta.json (3)
│   │   ├── 5S (3)
│   │   │   └── meta.json (3)
│   │   ├── 6S (3)
│   │   │   └── meta.json (3)
│   │   ├── 7S (3)
│   │   │   └── meta.json (3)
│   │   ├── 8S (3)
│   │   │   └── meta.json (3)
│   │   └── 9S (3)
│   │       │   └── meta.json (3)
│   └── 1M (141)
│       │   ├── 0S (3)
│       │   │   └── meta.json (3)
│       │   ├── 10S (3)
│       │   │   └── meta.json (3)
│       │   ├── 11S (3)
│       │   │   └── meta.json (3)
│       │   ├── 12S (3)
│       │   │   └── meta.json (3)
│       │   ├── 13S (3)
│       │   │   └── meta.json (3)
│       │   ├── 14S (3)
│       │   │   └── meta.json (3)
│       │   ├── 15S (3)
│       │   │   └── meta.json (3)
│       │   ├── 16S (3)
│       │   │   └── meta.json (3)
│       │   ├── 17S (3)
│       │   │   └── meta.json (3)
│       │   ├── 18S (3)
│       │   │   └── meta.json (3)
│       │   ├── 19S (3)
│       │   │   └── meta.json (3)
│       │   ├── 1S (3)
│       │   │   └── meta.json (3)
│       │   ├── 20S (3)
│       │   │   └── meta.json (3)
│       │   ├── 21S (3)
│       │   │   └── meta.json (3)
│       │   ├── 22S (3)
│       │   │   └── meta.json (3)
│       │   ├── 23S (3)
│       │   │   └── meta.json (3)
│       │   ├── 24S (3)
│       │   │   └── meta.json (3)
│       │   ├── 25S (3)
│       │   │   └── meta.json (3)
│       │   ├── 26S (3)
│       │   │   └── meta.json (3)
│       │   ├── 27S (3)
│       │   │   └── meta.json (3)
│       │   ├── 28S (3)
│       │   │   └── meta.json (3)
│       │   ├── 29S (3)
│       │   │   └── meta.json (3)
│       │   ├── 2S (3)
│       │   │   └── meta.json (3)
│       │   ├── 30S (3)
│       │   │   └── meta.json (3)
│       │   ├── 31S (3)
│       │   │   └── meta.json (3)
│       │   ├── 32S (3)
│       │   │   └── meta.json (3)
│       │   ├── 33S (3)
│       │   │   └── meta.json (3)
│       │   ├── 34S (3)
│       │   │   └── meta.json (3)
│       │   ├── 35S (3)
│       │   │   └── meta.json (3)
│       │   ├── 36S (3)
│       │   │   └── meta.json (3)
│       │   ├── 37S (3)
│       │   │   └── meta.json (3)
│       │   ├── 38S (3)
│       │   │   └── meta.json (3)
│       │   ├── 39S (3)
│       │   │   └── meta.json (3)
│       │   ├── 3S (3)
│       │   │   └── meta.json (3)
│       │   ├── 40S (3)
│       │   │   └── meta.json (3)
│       │   ├── 41S (3)
│       │   │   └── meta.json (3)
│       │   ├── 42S (3)
│       │   │   └── meta.json (3)
│       │   ├── 43S (3)
│       │   │   └── meta.json (3)
│       │   ├── 44S (3)
│       │   │   └── meta.json (3)
│       │   ├── 45S (3)
│       │   │   └── meta.json (3)
│       │   ├── 46S (3)
│       │   │   └── meta.json (3)
│       │   ├── 47S (3)
│       │   │   └── meta.json (3)
│       │   ├── 48S (3)
│       │   │   └── meta.json (3)
│       │   ├── 49S (3)
│       │   │   └── meta.json (3)
│       │   ├── 4S (3)
│       │   │   └── meta.json (3)
│       │   ├── 50S (3)
│       │   │   └── meta.json (3)
│       │   ├── 51S (3)
│       │   │   └── meta.json (3)
│       │   └── 52S (0)
└── LADYBIRD.xml (8)
----
----
Full Path: LADYBIRD.xml

<Clip_Manifest NumDirs="498">
  <_1 Name="CLIP2" In="1.6261465427355111E-307" InIdx="228" Out="1.6261466707242047E-307" OutIdx="4110" Locked="True" InStr="07:27:16.618 08/13/2024" Epoch="1723559236.618" Pos="0H/0M/3.8S/" />
  <_2 Name="CLIP1" In="1.6261465850368715E-307" InIdx="1511" Out="1.6261470057932999E-307" OutIdx="14273" Locked="True" InStr="07:27:38.022 08/13/2024" Epoch="1723559258.0219998" Pos="0H/0M/25.1833333333333S/" />
  <_3 Name="CLIP3" In="1.6261501214407288E-307" InIdx="14658" Out="1.6261501214407288E-307" OutIdx="14658" Locked="True" InStr="07:57:27.463 08/13/2024" Epoch="1723561047.4629998" Pos="0H/4M/4.30000000000001S/" />
  <_4 Name="CLIP4" In="1.6261504029336424E-307" InIdx="15096" Out="1.6261504567393675E-307" OutIdx="16728" Locked="True" InStr="07:59:49.900 08/13/2024" Epoch="1723561189.8999999" Pos="0H/4M/11.6S/" />
  <_5 Name="CLIP6" In="1.626151890120643E-307" InIdx="17124" Out="1.6261520105896575E-307" OutIdx="20778" Locked="True" InStr="08:12:22.425 08/13/2024" Epoch="1723561942.425" Pos="0H/4M/45.4S/" />
  <_6 Name="CLIP7" In="1.6261529151745092E-307" InIdx="21221" Out="1.6261531935026773E-307" OutIdx="29663" Locked="True" InStr="08:21:01.108 08/13/2024" Epoch="1723562461.108" Pos="0H/5M/53.6833333333333S/" />
</Clip_Manifest>

----
Full Path: 0H/1M/43S/meta.json

{
"Time":{"x0":1723559335.914, "xi-x0":[0,0.017,0.033,0.050,0.067,0.083,0.100,0.117,0.133,0.150,0.167,0.183,0.200,0.217,0.233,0.250,0.267,0.284,0.300,0.317,0.334,0.350,0.367,0.384,0.400,0.417,0.434,0.450,0.467,0.484,0.500,0.517,0.534,0.550,0.567,0.584,0.601,0.617,0.634,0.651,0.667,0.684,0.701,0.717,0.734,0.751,0.767,0.784,0.801,0.817,0.834,0.851,0.867,0.884,0.901,0.917,0.934,0.951,0.968,0.984]}
}

----
Full Path: 0H/1M/44S/meta.json

{
"Time":{"x0":1723559336.915, "xi-x0":[0,0.017,0.033,0.050,0.067,0.083,0.100,0.117,0.133,0.150,0.167,0.183,0.200,0.217,0.233,0.250,0.267,0.284,0.300,0.317,0.334,0.350,0.367,0.384,0.400,0.417,0.434,0.450,0.467,0.484,0.500,0.517,0.534,0.550,0.567,0.584,0.600,0.617,0.634,0.651,0.667,0.684,0.701,0.717,0.734,0.751,0.767,0.784,0.801,0.817,0.834,0.851,0.867,0.884,0.901,0.917,0.934,0.951,0.968,0.984]}
}
```


---

# COSM C360 Tools Project Context

## Overview
The COSM C360 Tools project (`cosmos`) is a utility for converting specialized video output from COSM C360 cameras (commonly used in professional sports production, e.g., NFL pylon cameras) into standard MP4 format. The tool processes the camera's unique output format, which consists of multiple tiled HEVC streams with accompanying metadata.

## Target Users
- **Primary Users**: Ecologists and scientists deploying these cameras for field research
- **Technical Level**: Non-technical users who need to review footage before submitting to main analysis pipeline
- **Use Case**: Converting raw camera format to standard MP4s for review and ingest into ecological analysis tools

## User Considerations
1. **Technical Expertise**
   - Users are not technically sophisticated
   - Need simple, guided interface
   - Should handle errors gracefully with clear explanations
   - Must provide clear feedback about processing status

2. **System Requirements**
   - Must support Windows (primary platform for users)
   - Must work on low-end systems (not workstation-grade machines)
   - Should provide options for memory-constrained systems
   - Should automatically detect and use best available encoding options

3. **Workflow Integration**
   - Tool will eventually be integrated into main ecological analysis software
   - Currently needed as standalone utility for pre-processing
   - Should maintain compatibility with analysis pipeline requirements

## Key Requirements Beyond Technical Specs

1. **Usability**
   - Interactive mode for guided operation
   - Clear progress indication
   - Informative error messages
   - Pre-flight validation to catch issues early
   - No technical knowledge required for basic operation

2. **Robustness**
   - Automatic encoder selection and fallback
   - Handles partial or corrupted data gracefully
   - Works across different platforms
   - Adapts to available system resources

3. **System Adaptation**
   - Automatic detection of optimal settings
   - Low-memory mode for constrained systems
   - Fallback to software encoding if hardware encoding unavailable
   - Clear warnings about system requirements

4. **Error Handling**
   - Clear, non-technical error messages
   - Validation before processing starts
   - Helpful suggestions for resolving issues
   - Graceful handling of partial or corrupted data

## Development Priorities
1. **Core Functionality**
   - Reliable video processing
   - Robust input validation
   - Cross-platform compatibility
   - Memory usage optimization

2. **User Experience**
   - Simple, guided interface
   - Clear progress reporting
   - Informative feedback
   - Error resilience

3. **Optional Enhancements**
   - Configuration saving
   - Processing resumption
   - Automated updates
   - Additional format support

## Deployment Considerations
- Tool will be distributed via public repository
- Users will need to pull repo and follow installation instructions
- Should minimize external dependencies
- Must include clear installation and usage documentation
- Should provide support for common issues

## Integration Context
This tool is part of a larger ecological analysis pipeline:
1. Raw footage captured with COSM C360 cameras
2. Conversion to standard MP4 format (this tool)
3. Ingestion into ecological analysis software
4. Analysis of ecological activity in footage

## Future Considerations
- Tool may be integrated directly into main analysis software
- May need to handle additional camera formats
- Could expand to support batch processing
- Might need additional output format options

----
Full Path: pyproject.toml

[project]
name = "cosm-c360-tools"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "psutil>=6.1.0",
    "questionary>=2.0.1",
]


----
Full Path: TESTING.md

# Testing the COSM C360 Tools

This document outlines how to run tests on macOS, Linux, and Windows.

## Requirements

- Python 3.10 or higher
- `pytest` installed in your environment
- `ffmpeg` installed and accessible in `PATH`
- The input directory specified for integration tests (`/datasets/dataZoo/clients/ladybird_data/LADYBIRD/failed_copy`) must be accessible on your machine.
- The output directory (`/datasets/dataZoo/clients/ladybird_data/LADYBIRD/cosmos_out`) must exist and be writable.

## Installing Test Dependencies

If you used `uv` (recommended):

```bash
# On macOS and Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
uv new cosmos-env
uv activate cosmos-env
pip install -r requirements.txt

# On Windows (PowerShell)
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
uv new cosmos-env
uv activate cosmos-env
pip install -r requirements.txt
```

If not using `uv`, you can use `python -m venv` and `pip` as documented in the README.

## Running Tests

To run all tests:
```bash
pytest tests
```

This will run:
- Unit tests for manifest, validation, processing.
- The integration test (`test_integration.py`).

If the integration test fails, ensure that:
- The specified input and output directories are accessible.
- FFmpeg is installed and in `PATH`.
- You have sufficient system resources (disk space, etc.).

## Platform Notes

- **macOS & Linux**: Should work out of the box with `pytest`.
- **Windows**: Ensure Python and ffmpeg are installed, and that `ffmpeg` is in `PATH`. Running `pytest` in `powershell` or `cmd` is supported.

## Additional Tips

- Use `-v` for verbose output:
  ```bash
  pytest -v tests
  ```
- Use `-k` to run a specific test:
  ```bash
  pytest -k test_self_test_integration
  ```

----
Full Path: README.md

# COSM C360 Tools

**COSM C360 Tools** (referred to as `cosmos`) is a command-line utility for converting specialized video output from COSM C360 cameras into standard MP4 video files suitable for review and downstream analysis. It handles the complex tiled HEVC output and merges multiple streams into a standard video format.

## Key Features

- **Manifest Parsing & Validation**: Automatically finds and parses the camera's XML manifest file, identifying clips and verifying temporal continuity.
- **Segment Analysis**: Gathers `.ts` segments and their corresponding `meta.json` files, ensuring integrity and completeness.
- **Video Assembly**: Extracts and aligns four HEVC tile streams, handles overlapping regions, and assembles frames into a full-resolution video.
- **Multi-Resolution Output**: Outputs a full-resolution master file and can generate downscaled variants (e.g., 4K, 1080p).
- **Cross-Platform & Hardware Acceleration**: Works on Linux, macOS, and Windows. Automatically attempts hardware-accelerated encoding (NVENC, AMF, QSV) and falls back to software (x264).
- **Pre-Flight Checks**: Built-in `--self-test` mode checks system requirements (FFmpeg, disk space, memory) and input directory structure before processing.
- **Interactive & Non-Interactive Modes**: Fully scriptable via CLI flags, or run interactively with guided prompts for non-technical users.
- **Update Checking**: Checks for updates if `git` is available.

## System Requirements

- **Operating System**: Linux, macOS, or Windows.
- **Python**: 3.10 or higher recommended.
- **FFmpeg**: Must be installed and accessible in `PATH`.
- **Memory**: At least 8GB RAM recommended (less may cause slowdowns, consider `--low-memory` mode).
- **Disk Space**: At least 10GB free disk space recommended.
- **Git (Optional)**: To automatically check for updates when running `--check-updates`.

## Input Directory Structure

The input directory should follow a hierarchical structure reflecting the camera output:

```
input_dir/
 ├── 0H/
 │   ├── 0M/
 │   │   ├── 0S/
 │   │   │   ├── meta.json
 │   │   │   ├── <segment .ts files>
 │   │   ├── 1S/
 │   │   │   ├── meta.json
 │   │   │   ├── <segment .ts files>
 │   │   └── ...
 │   └── 1M/
 │       ├── 0S/
 │       │   ├── meta.json
 │       │   ├── <segment .ts files>
 │       └── ...
 ├── MyManifest.xml
 └── AnotherManifest.xml (if multiple manifests exist)
```

- Each second-level directory (`XH/XM/XS`) must contain a `meta.json` file and `.ts` files.
- The top-level directory should contain a single `.xml` manifest file. If multiple `.xml` files are present, you must specify which one to use via `--manifest`.

## Installation

We recommend using [UV](https://github.com/astral-sh/uv?tab=readme-ov-file) for environment management.

### Using UV (Recommended)

**macOS / Linux**:
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
uv new cosmos-env
uv activate cosmos-env
pip install -r requirements.txt
```

**Windows (PowerShell)**:
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
uv new cosmos-env
uv activate cosmos-env
pip install -r requirements.txt
```

If not using UV, you can still use Python's built-in `venv`:
```bash
# On macOS/Linux:
python3 -m venv venv
source venv/bin/activate

# On Windows:
python -m venv venv
venv\Scripts\activate

pip install -r requirements.txt
```

Confirm `ffmpeg` is installed and in your PATH:
```bash
ffmpeg -version
```

If `ffmpeg` is not found, please install it according to your platform's instructions.

## Usage

### Non-Interactive Mode

Run `cosmos.py` directly or via `python`:

```bash
python cosmos.py --input-dir /path/to/input --output-dir /path/to/output
```

If multiple `.xml` manifests exist, specify which one:
```bash
python cosmos.py --input-dir /path/to/input --output-dir /path/to/output --manifest /path/to/manifest.xml
```

Run a system self-test before processing:
```bash
python cosmos.py --input-dir /path/to/input --output-dir /path/to/output --self-test
```

Check for updates:
```bash
python cosmos.py --check-updates
```

Specify a job name (useful for logs and output notes):
```bash
python cosmos.py --input-dir /path/to/input --output-dir /path/to/output --job-name MyJobName
```

Adjust logging:
```bash
python cosmos.py --input-dir /path/to/input --output-dir /path/to/output --log-level DEBUG --log-file mylog.log
```

### Interactive Mode

If you're unsure about the input directory or other parameters, run:
```bash
python cosmos.py --interactive
```

The tool will guide you through selecting the input directory, output directory, and other settings interactively. After confirming, it will proceed with processing.

### Example Commands (All Platforms)

**Windows (PowerShell)**:
```powershell
python .\cosmos.py --input-dir C:\data\cosm_input --output-dir C:\data\cosm_output --self-test
```

**macOS / Linux (Bash)**:
```bash
python cosmos.py --input-dir ~/cosm_input --output-dir ~/cosm_output --interactive
```

## Running Tests

Tests are included to ensure code quality and correctness:

```bash
pytest tests
```

Ensure `pytest` is installed:
```bash
pip install pytest
```

This runs the test suite (unit tests for validation, processing, manifest parsing, and integration tests). Use `TESTING.md` for more detailed testing instructions.

## Additional Notes

- Output files, including `job_info.txt`, are placed in the specified `output` directory.
- If system resources are limited, consider `--low-memory` mode (to be added) or reducing resolution.
- If you wish to contribute or request features, please open an issue or a pull request.

----
Full Path: src/cosmos/validation.py

from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
import json
import shutil
import subprocess
from datetime import datetime

from .manifest import ClipInfo, ClipStatus, Position, ManifestParser

class ValidationLevel(Enum):
    """Severity level for validation issues"""
    ERROR = "error"          # Fatal issue, cannot proceed
    WARNING = "warning"      # Potential issue, can proceed with caution
    INFO = "info"           # Informational note

@dataclass
class ValidationIssue:
    """Details about a validation problem"""
    level: ValidationLevel
    message: str
    context: Optional[str] = None
    help_text: Optional[str] = None

@dataclass
class SegmentInfo:
    """Information about a video segment from meta.json"""
    directory: Path
    start_time: float
    frame_timestamps: List[float]
    ts_files: List[Path]
    
    @property
    def end_time(self) -> float:
        """Get end time of segment from last frame timestamp"""
        return self.frame_timestamps[-1] if self.frame_timestamps else self.start_time
    
    @property
    def frame_count(self) -> int:
        """Number of frames in segment"""
        return len(self.frame_timestamps)
    
    @property
    def has_all_files(self) -> bool:
        """Check if all expected .ts files are present"""
        return len(self.ts_files) == self.frame_count

@dataclass
class ClipValidationResult:
    """Validation results for a single clip"""
    clip: ClipInfo
    segments: List[SegmentInfo]
    missing_segments: List[Position]
    issues: List[ValidationIssue]
    estimated_size: int  # in bytes
    
    @property
    def is_valid(self) -> bool:
        """Check if clip has enough valid data to process"""
        return bool(self.segments) and not any(
            issue.level == ValidationLevel.ERROR 
            for issue in self.issues
        )

@dataclass
class ValidationResult:
    """Complete validation results for input directory"""
    system_issues: List[ValidationIssue]
    clip_results: Dict[str, ClipValidationResult]
    total_size_estimate: int
    available_space: int
    
    @property
    def can_proceed(self) -> bool:
        """Check if processing can proceed with any clips"""
        return (
            not any(i.level == ValidationLevel.ERROR for i in self.system_issues)
            and any(r.is_valid for r in self.clip_results.values())
            and self.available_space > self.total_size_estimate
        )

class InputValidator:
    """
    Validates input data and system requirements for COSM video processing.
    
    Performs checks at multiple levels:
    1. System requirements (ffmpeg, space, etc.)
    2. Input directory structure
    3. Clip data integrity
    4. Segment availability and validity
    """
    
    def __init__(self, 
                 input_dir: Path,
                 output_dir: Path,
                 manifest_parser: ManifestParser):
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.manifest_parser = manifest_parser
        
    def validate_system(self) -> List[ValidationIssue]:
        """Check system requirements"""
        issues = []
        
        # Check ffmpeg installation
        try:
            subprocess.run(
                ["ffmpeg", "-version"], 
                capture_output=True, 
                check=True
            )
        except subprocess.CalledProcessError:
            issues.append(ValidationIssue(
                level=ValidationLevel.ERROR,
                message="FFmpeg not found",
                help_text="Please install FFmpeg to process videos"
            ))
        except FileNotFoundError:
            issues.append(ValidationIssue(
                level=ValidationLevel.ERROR,
                message="FFmpeg not found in system PATH",
                help_text="Please install FFmpeg and ensure it's in your PATH"
            ))
            
        # Check output directory
        try:
            self.output_dir.mkdir(parents=True, exist_ok=True)
            test_file = self.output_dir / ".write_test"
            test_file.touch()
            test_file.unlink()
        except Exception as e:
            issues.append(ValidationIssue(
                level=ValidationLevel.ERROR,
                message=f"Cannot write to output directory: {e}",
                help_text="Check permissions and disk space"
            ))
            
        return issues
    
    def validate_segment(self, 
                        segment_dir: Path) -> Optional[SegmentInfo]:
        """
        Validate a segment directory and its meta.json
        
        Args:
            segment_dir: Path to segment directory
            
        Returns:
            SegmentInfo if valid, None if invalid
        """
        meta_path = segment_dir / "meta.json"
        if not meta_path.is_file():
            return None
            
        try:
            with open(meta_path) as f:
                meta = json.load(f)
                
            if "Time" not in meta or "x0" not in meta["Time"] or "xi-x0" not in meta["Time"]:
                return None
                
            start_time = meta["Time"]["x0"]
            increments = meta["Time"]["xi-x0"]
            
            # Get all .ts files in directory
            ts_files = sorted(segment_dir.glob("*.ts"))
            
            # Create timestamps for each frame
            timestamps = [start_time + inc for inc in increments]
            
            return SegmentInfo(
                directory=segment_dir,
                start_time=start_time,
                frame_timestamps=timestamps,
                ts_files=ts_files
            )
            
        except (json.JSONDecodeError, KeyError, TypeError):
            return None
    
    def validate_clip(self, clip: ClipInfo) -> ClipValidationResult:
        """
        Validate all segments for a clip
        
        Args:
            clip: ClipInfo object to validate
            
        Returns:
            ClipValidationResult with validation details
        """
        issues = []
        segments = []
        missing_positions = []
        
        # Calculate expected segment positions
        start_sec = int(clip.start_pos.second)
        end_sec = int(clip.end_pos.second) if clip.end_pos else start_sec + 60
        
        for second in range(start_sec, end_sec + 1):
            pos = Position(
                hour=clip.start_pos.hour,
                minute=clip.start_pos.minute,
                second=second
            )
            
            # Check if segment exists
            segment_dir = self.input_dir / pos.path_fragment()
            if not segment_dir.is_dir():
                missing_positions.append(pos)
                continue
                
            # Validate segment
            if segment_info := self.validate_segment(segment_dir):
                segments.append(segment_info)
            else:
                issues.append(ValidationIssue(
                    level=ValidationLevel.WARNING,
                    message=f"Invalid segment at {pos.path_fragment()}",
                    context="Missing or corrupt meta.json"
                ))
        
        # Estimate output size (very rough approximation)
        # Assume ~100MB per second of full-res output
        estimated_size = len(segments) * 100 * 1024 * 1024
        
        return ClipValidationResult(
            clip=clip,
            segments=segments,
            missing_segments=missing_positions,
            issues=issues,
            estimated_size=estimated_size
        )
    
    def validate_all(self) -> ValidationResult:
        """
        Perform complete validation of system and input data
        
        Returns:
            ValidationResult with all validation details
        """
        # Check system requirements
        system_issues = self.validate_system()
        
        # Validate each clip
        clip_results = {}
        total_size = 0
        
        for clip in self.manifest_parser.get_clips():
            result = self.validate_clip(clip)
            clip_results[clip.name] = result
            total_size += result.estimated_size
            
            # Update clip status based on validation
            if not result.segments:
                clip.status = ClipStatus.MISSING
            elif result.missing_segments:
                clip.status = ClipStatus.PARTIAL
            else:
                clip.status = ClipStatus.COMPLETE
        
        # Check available space
        try:
            available = shutil.disk_usage(self.output_dir).free
        except Exception:
            available = 0
            system_issues.append(ValidationIssue(
                level=ValidationLevel.ERROR,
                message="Cannot determine available disk space",
                help_text="Check output directory permissions"
            ))
        
        return ValidationResult(
            system_issues=system_issues,
            clip_results=clip_results,
            total_size_estimate=total_size,
            available_space=available
        )

----
Full Path: src/cosmos/utils.py

# File: src/cosmos/utils.py

import logging
import json
import subprocess
import shutil
import sys
from pathlib import Path
from typing import Any, Dict, Optional

__version__ = "0.2.1"  # Just an example version

def init_logging(level: str = "INFO", logfile: Optional[Path] = None) -> logging.Logger:
    logger = logging.getLogger("cosmos")
    logger.setLevel(getattr(logging, level.upper(), logging.INFO))
    logger.handlers.clear()
    logger.propagate = False

    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(getattr(logging, level.upper(), logging.INFO))
    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
    ch.setFormatter(formatter)
    logger.addHandler(ch)

    if logfile:
        fh = logging.FileHandler(logfile, encoding='utf-8')
        fh.setLevel(getattr(logging, level.upper(), logging.INFO))
        fh.setFormatter(formatter)
        logger.addHandler(fh)

    return logger

def load_config(config_path: Path) -> Dict[str, Any]:
    if config_path.is_file():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError):
            return {}
    return {}

def save_config(config_path: Path, config: Dict[str, Any]) -> None:
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2)

def check_ffmpeg() -> bool:
    try:
        subprocess.run(["ffmpeg", "-version"], check=True, capture_output=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False

def is_git_available() -> bool:
    return shutil.which("git") is not None

def check_for_updates(repo_path: Path) -> bool:
    """
    Check if updates are available for a Git repository.
    Returns True if an update is available, False otherwise.
    If any error occurs, returns False.
    """
    try:
        # 'git fetch' to update remote refs
        subprocess.run(["git", "-C", str(repo_path), "fetch"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        remote_head = subprocess.check_output(["git", "-C", str(repo_path), "ls-remote", "origin", "HEAD"], text=True).split()[0]
        local_head = subprocess.check_output(["git", "-C", str(repo_path), "rev-parse", "HEAD"], text=True).strip()
        return remote_head != local_head
    except Exception as e:
        print_error(f"Error checking for updates: {e}")
        return False

def check_updates(repo_path: Path = Path(".")) -> None:
    print_info(f"Current version: {__version__}")
    if is_git_available():
        if check_for_updates(repo_path):
            print_info("An update is available! Run `git pull` to update.")
        else:
            print_info("You are up-to-date.")
    else:
        print_warning("Git is not installed or not accessible. Cannot check for updates.")
        print_info("Visit the repository and `git pull` manually to update.")

def print_info(message: str) -> None:
    print(f"[INFO] {message}")

def print_warning(message: str) -> None:
    print(f"[WARNING] {message}")

def print_error(message: str) -> None:
    print(f"[ERROR] {message}", file=sys.stderr)

def print_success(message: str) -> None:
    print(f"[SUCCESS] {message}")


----
Full Path: src/cosmos/manifest.py

from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import xml.etree.ElementTree as ET


class ClipStatus(Enum):
    """Status of a clip's data availability"""
    COMPLETE = "complete"          # All expected segments present
    PARTIAL = "partial"           # Some segments missing
    MISSING = "missing"           # No segments found
    INVALID = "invalid"           # Metadata inconsistency detected


@dataclass
class Position:
    """
    Represents a position in the COSM directory structure.
    
    Format is typically "NH/MM/SS.sss" where:
    - N: Hour number
    - MM: Minute number
    - SS.sss: Second with fractional component
    """
    hour: int
    minute: int
    second: float

    @classmethod
    def from_string(cls, pos_str: str) -> "Position":
        """Parse a position string like '0H/0M/3.8S/'"""
        parts = pos_str.strip('/').split('/')
        if len(parts) != 3:
            raise ValueError(f"Invalid position string format: {pos_str}")
        
        try:
            hour = int(parts[0].rstrip('H'))
            minute = int(parts[1].rstrip('M'))
            second = float(parts[2].rstrip('S'))
            return cls(hour=hour, minute=minute, second=second)
        except (ValueError, IndexError) as e:
            raise ValueError(f"Failed to parse position string: {pos_str}") from e

    def to_string(self) -> str:
        """Convert position back to string format"""
        return f"{self.hour}H/{self.minute}M/{self.second}S"
    
    def to_seconds(self) -> float:
        """Convert position to total seconds from start of hour"""
        return self.hour * 3600 + self.minute * 60 + self.second


@dataclass
class ClipInfo:
    """
    Information about a single clip from the manifest.
    
    Clips represent continuous recording sessions, each containing multiple
    video segments that should be processed together.
    """
    name: str                     # Clip identifier (e.g., "CLIP1")
    start_epoch: float           # Start timestamp (Unix epoch)
    end_epoch: float             # End timestamp (Unix epoch)
    start_pos: Position          # Starting directory position
    end_pos: Position            # Ending directory position
    start_idx: int              # Starting frame index
    end_idx: int                # Ending frame index
    start_time: datetime        # Human-readable start time
    status: ClipStatus = ClipStatus.MISSING

    @property
    def duration(self) -> float:
        """Duration of clip in seconds"""
        return self.end_epoch - self.start_epoch

    @property
    def frame_count(self) -> int:
        """Total number of frames in clip"""
        return self.end_idx - self.start_idx


class ManifestParser:
    """
    Parser for COSM C360 camera clip manifests.
    
    The manifest XML contains information about recording sessions ("clips"),
    including their temporal boundaries, frame indices, and positions within
    the directory structure.
    """
    
    def __init__(self, manifest_path: Path):
        """
        Initialize parser with path to manifest XML.
        
        Args:
            manifest_path: Path to the manifest XML file
            
        Raises:
            FileNotFoundError: If manifest file doesn't exist
            xml.etree.ElementTree.ParseError: If XML is malformed
        """
        self.manifest_path = manifest_path
        self._clips: Dict[str, ClipInfo] = {}
        
        if not manifest_path.exists():
            raise FileNotFoundError(f"Manifest not found: {manifest_path}")
        
        self._parse_manifest()
    
    def _parse_manifest(self) -> None:
        """
        Parse the manifest XML file and extract clip information.
        
        The manifest contains a series of clip entries with attributes:
        - Name: Clip identifier
        - Epoch: Start time in Unix epoch format
        - Pos: Directory position string
        - InIdx/OutIdx: Frame index boundaries
        - InStr: Human-readable timestamp
        """
        tree = ET.parse(self.manifest_path)
        root = tree.getroot()
        
        for elem in root:
            try:
                name = elem.attrib['Name']
                start_epoch = float(elem.attrib['Epoch'])
                pos = Position.from_string(elem.attrib['Pos'])
                start_idx = int(elem.attrib['InIdx'])
                end_idx = int(elem.attrib['OutIdx'])
                start_time = datetime.strptime(
                    elem.attrib['InStr'],
                    "%H:%M:%S.%f %m/%d/%Y"
                )
                
                # Store clip info
                self._clips[name] = ClipInfo(
                    name=name,
                    start_epoch=start_epoch,
                    end_epoch=None,  # Will be determined from segment data
                    start_pos=pos,
                    end_pos=None,    # Will be determined from segment data
                    start_idx=start_idx,
                    end_idx=end_idx,
                    start_time=start_time
                )
                
            except (KeyError, ValueError) as e:
                # Log warning but continue parsing other clips
                print(f"Warning: Failed to parse clip element: {e}")
                continue
    
    def get_clip(self, name: str) -> Optional[ClipInfo]:
        """Get information for a specific clip by name"""
        return self._clips.get(name)
    
    def get_clips(self) -> List[ClipInfo]:
        """Get list of all clips in temporal order"""
        return sorted(
            self._clips.values(),
            key=lambda x: x.start_epoch
        )
    
    def update_clip_status(self, name: str, status: ClipStatus) -> None:
        """Update the status of a clip after validation"""
        if clip := self._clips.get(name):
            clip.status = status
    
    def find_clip_for_timestamp(self, timestamp: float) -> Optional[ClipInfo]:
        """Find the clip containing a given timestamp"""
        for clip in self._clips.values():
            if clip.start_epoch <= timestamp and (
                clip.end_epoch is None or timestamp <= clip.end_epoch
            ):
                return clip
        return None


def find_manifest(base_dir: Path) -> Optional[Path]:
    """
    Find the COSM manifest XML file in a directory.
    
    Args:
        base_dir: Directory to search for manifest
        
    Returns:
        Path to manifest if exactly one is found, None otherwise
        
    Raises:
        ValueError: If multiple manifest files are found
    """
    manifests = list(base_dir.glob("**/*.xml"))
    
    if not manifests:
        return None
    
    if len(manifests) > 1:
        raise ValueError(
            f"Multiple manifest files found: {', '.join(str(p) for p in manifests)}"
        )
    
    return manifests[0]

----
Full Path: src/cosmos/cli.py

# File: src/cosmos/cli.py

import argparse
from pathlib import Path
import sys
import logging

from typing import Optional

from .utils import (
    init_logging,
    load_config,
    save_config,
    self_test,
    check_updates,
    check_ffmpeg,
    print_info,
    print_warning,
    print_error,
    print_success
)

# questionary is optional, ensure safe import:
try:
    import questionary
except ImportError:
    questionary = None

def parse_args():
    parser = argparse.ArgumentParser(description="COSM C360 Tools CLI")
    parser.add_argument("--input-dir", type=str, help="Path to input directory containing raw segments")
    parser.add_argument("--output-dir", type=str, help="Path to output directory where processed files will be saved")
    parser.add_argument("--manifest", type=str, help="Path to manifest file if not discoverable automatically")
    parser.add_argument("--config-file", type=str, help="Path to a configuration file (JSON)")
    parser.add_argument("--log-file", type=str, help="Path to a logfile")
    parser.add_argument("--log-level", type=str, default="INFO", help="Logging level (DEBUG, INFO, WARNING, ERROR)")
    parser.add_argument("--interactive", action="store_true", help="Run in interactive mode")
    parser.add_argument("--self-test", action="store_true", help="Run a self-test and exit")
    parser.add_argument("--check-updates", action="store_true", help="Check for updates and exit")

    return parser.parse_args()

def run_interactive_mode(config: dict) -> dict:
    """
    Run an interactive session to gather input_dir, output_dir, and other settings.
    Uses questionary for cross-platform interactive prompts.
    If questionary not installed, fallback is to print an error and exit.
    """
    if questionary is None:
        print_error("Interactive mode requested but 'questionary' is not installed.")
        sys.exit(1)

    print_info("Entering interactive mode...")

    # Prompt for input directory
    input_dir = questionary.path(
        "Please select the input directory containing raw segments:",
        default=str(config.get("input_dir", ""))
    ).ask()

    # Prompt for output directory
    output_dir = questionary.path(
        "Please select the output directory for processed files:",
        default=str(config.get("output_dir", ""))
    ).ask()

    # Confirm ffmpeg available
    if not check_ffmpeg():
        print_warning("FFmpeg not found. Please install it before proceeding.")
        questionary.confirm("Do you want to continue anyway?", default=False).ask()

    # Prompt for log level
    log_level = questionary.select(
        "Select log level:",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default=config.get("log_level", "INFO")
    ).ask()

    config["input_dir"] = input_dir
    config["output_dir"] = output_dir
    config["log_level"] = log_level

    # Confirm final settings
    print_info("Review your settings:")
    print_info(f"  Input Directory: {config['input_dir']}")
    print_info(f"  Output Directory: {config['output_dir']}")
    print_info(f"  Log Level: {config['log_level']}")
    confirm = questionary.confirm("Proceed with these settings?", default=True).ask()

    if not confirm:
        print_info("Aborted by user.")
        sys.exit(0)

    return config

def main():
    args = parse_args()

    # Load config if provided
    config_path = Path(args.config_file) if args.config_file else None
    config = load_config(config_path) if config_path else {}

    # Command line args override config or fill in missing fields
    if args.log_level:
        config["log_level"] = args.log_level
    if args.log_file:
        config["log_file"] = args.log_file
    if args.input_dir:
        config["input_dir"] = args.input_dir
    if args.output_dir:
        config["output_dir"] = args.output_dir
    if args.manifest:
        config["manifest"] = args.manifest

    # Initialize logging
    logfile = Path(config["log_file"]) if "log_file" in config else None
    logger = init_logging(level=config.get("log_level", "INFO"), logfile=logfile)

    # Handle special commands first
    if args.self_test:
        success = self_test(
            input_dir=Path(config["input_dir"]) if "input_dir" in config else None,
            output_dir=Path(config["output_dir"]) if "output_dir" in config else None
        )
        sys.exit(0 if success else 1)

    if args.check_updates:
        check_updates()
        sys.exit(0)

    # If interactive mode requested, run interactive prompts
    if args.interactive:
        config = run_interactive_mode(config)

    # Validate that we have required directories
    if "input_dir" not in config or not config["input_dir"]:
        print_error("Input directory not specified. Use --input-dir or run in interactive mode.")
        sys.exit(1)

    if "output_dir" not in config or not config["output_dir"]:
        print_error("Output directory not specified. Use --output-dir or run in interactive mode.")
        sys.exit(1)

    input_dir = Path(config["input_dir"])
    output_dir = Path(config["output_dir"])

    # Save updated config if config file provided
    if config_path:
        save_config(config_path, config)

    # From here we would:
    # 1. Use manifest parser to find or load manifest.
    # 2. Validate inputs using InputValidator.
    # 3. Process clips using VideoProcessor.
    #
    # For now, we'll just log that we've completed CLI argument resolution.
    logger.info("CLI argument resolution complete. Ready to proceed with processing pipeline.")
    logger.info(f"Input Directory: {input_dir}")
    logger.info(f"Output Directory: {output_dir}")
    if "manifest" in config:
        logger.info(f"Manifest: {config['manifest']}")

    # The next step would be calling into the main cosmos pipeline (e.g. from cosmos.py)
    # This might look like:
    # 
    # from .manifest import find_manifest, ManifestParser
    # from .validation import InputValidator
    # from .processor import VideoProcessor, ProcessingOptions, ProcessingMode
    #
    # # ... load manifest, validate, process, etc.
    #
    # For now, we leave this as is.

if __name__ == "__main__":
    main()


----
Full Path: src/cosmos/preflight.py

# File: src/cosmos/preflight.py

import platform
import os
import sys
import shutil
from pathlib import Path
import psutil
from typing import Optional

from .utils import print_info, print_warning, print_error, print_success, check_ffmpeg

def check_python_version(min_version=(3, 8)):
    return sys.version_info >= min_version

def check_system_memory(minimum_gb=8):
    total_memory = psutil.virtual_memory().total / (1024**3)
    return total_memory >= minimum_gb

def check_disk_space(directory: Path, minimum_gb=10):
    usage = shutil.disk_usage(directory)
    free_gb = usage.free / (1024**3)
    return free_gb >= minimum_gb

def check_required_codecs():
    # Assume ffmpeg install that we verified can run. Detailed codec check
    # could parse `ffmpeg -encoders` but omitted for brevity.
    return check_ffmpeg()

def check_directory_structure(input_dir: Path, manifest_path: Optional[Path] = None):
    """
    Basic directory structure checks:
    - Confirm input_dir exists
    - Confirm we have at least one .xml manifest if manifest_path not given
    - If multiple .xml manifests found and no manifest_path specified, fail
    - Check if we have at least one directory structure like NH/*M/*S/meta.json
    """
    if not input_dir.is_dir():
        return {
            "Directory Exists": {
                "check": False,
                "message": f"Input directory {input_dir} does not exist.",
                "help": "Check the input_dir path."
            }
        }
    
    # Check for manifest files if manifest_path not specified
    manifests = list(input_dir.glob("*.xml"))
    if manifest_path:
        # User specified manifest; check if it exists
        if not manifest_path.is_file():
            return {
                "Manifest Provided": {
                    "check": False,
                    "message": f"Specified manifest {manifest_path} not found.",
                    "help": "Ensure you provided the correct manifest path."
                }
            }
    else:
        # No manifest specified; must find exactly one
        if len(manifests) == 0:
            return {
                "Manifest Discovery": {
                    "check": False,
                    "message": "No .xml manifest found in top-level directory.",
                    "help": "Provide --manifest or place a single .xml in input_dir."
                }
            }
        elif len(manifests) > 1:
            return {
                "Manifest Ambiguity": {
                    "check": False,
                    "message": "Multiple .xml manifests found but none specified.",
                    "help": "Use --manifest to specify which manifest to use."
                }
            }

    # Check basic structure: at least one H directory, inside it at least one M directory, inside it at least one S directory with meta.json
    hour_dirs = [d for d in input_dir.glob("*H") if d.is_dir()]
    if not hour_dirs:
        return {
            "Directory Structure": {
                "check": False,
                "message": "No hour-level (e.g. '0H') directories found.",
                "help": "Ensure input_dir follows the 'NH/MM/SS' structure."
            }
        }

    # Check at least one M directory
    found_valid_structure = False
    for hdir in hour_dirs:
        mdirs = [m for m in hdir.glob("*M") if m.is_dir()]
        for mdir in mdirs:
            sdirs = [s for s in mdir.glob("*S") if s.is_dir()]
            for sdir in sdirs:
                meta = sdir / "meta.json"
                if meta.is_file():
                    found_valid_structure = True
                    break
            if found_valid_structure:
                break
        if found_valid_structure:
            break

    if not found_valid_structure:
        return {
            "Directory Structure": {
                "check": False,
                "message": "Did not find any second-level directories with meta.json.",
                "help": "Ensure the directory structure matches expected format (0H/0M/0S/meta.json)."
            }
        }

    return {
        "Directory Structure": {
            "check": True
        }
    }

def check_windows_specific(input_dir: Path):
    """
    On Windows, check if any paths exceed 260 chars.
    This can cause issues on older Windows environments.
    """
    if platform.system() == "Windows":
        for root, dirs, files in os.walk(input_dir):
            for name in dirs + files:
                full_path = Path(root, name)
                if len(str(full_path)) > 260:
                    return {
                        "Path Length": {
                            "check": False,
                            "message": f"Path exceeds 260 characters: {full_path}",
                            "help": "Shorten directory names or enable long paths in Windows."
                        }
                    }
    return {
        "Path Length": {"check": True}
    }

def validate_system_requirements(input_dir: Path, output_dir: Path):
    checks = {
        "FFmpeg Installation": {
            "check": check_ffmpeg(),
            "message": "FFmpeg not found. Please install it.",
            "help": "https://ffmpeg.org/download.html"
        },
        "HEVC Codec Availability": {
            "check": check_required_codecs(),
            "message": "HEVC codec support not found in ffmpeg.",
            "help": "Ensure your ffmpeg build supports HEVC."
        },
        "Python Version": {
            "check": check_python_version(),
            "message": "Python 3.8 or higher required.",
            "help": "Please upgrade your Python installation."
        },
        "System Memory": {
            "check": check_system_memory(minimum_gb=8),
            "message": "Less than 8GB RAM available. Processing may be slow.",
            "help": "Use --low-memory mode or upgrade system memory."
        },
        "Disk Space": {
            "check": check_disk_space(output_dir, minimum_gb=10),
            "message": "Less than 10GB disk space available.",
            "help": "Free disk space or choose another output directory."
        }
    }
    return checks

def format_validation_results(validation_results):
    all_good = True
    for category, result in validation_results.items():
        if not result["check"]:
            all_good = False
            print_error(f"[{category}] {result['message']} - {result.get('help', '')}")
        else:
            print_success(f"[{category}] OK")
    return all_good

def run_self_test(input_dir: Path, output_dir: Path, manifest_path: Optional[Path] = None) -> bool:
    print_info("Running system pre-flight checks...")
    system_checks = validate_system_requirements(input_dir, output_dir)
    sys_ok = format_validation_results(system_checks)

    print_info("Checking basic directory structure...")
    dir_checks = check_directory_structure(input_dir, manifest_path)
    dir_ok = format_validation_results(dir_checks)

    windows_ok = True
    if platform.system() == "Windows":
        print_info("Performing Windows-specific checks...")
        win_checks = check_windows_specific(input_dir)
        windows_ok = format_validation_results(win_checks)

    return sys_ok and dir_ok and windows_ok


----
Full Path: src/cosmos/processor.py

import os
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import subprocess
import tempfile
from datetime import datetime
import logging

from .validation import ClipValidationResult, SegmentInfo
from .manifest import ClipInfo

class ProcessingMode(Enum):
    QUALITY = "quality"        # Highest quality, all threads
    BALANCED = "balanced"      # Good quality, all threads
    PERFORMANCE = "speed"      # Faster, all threads
    LOW_MEMORY = "low_memory"  # Half threads
    MINIMAL = "minimal"        # Single thread

@dataclass
class ProcessingOptions:
    """Configuration for video processing"""
    output_resolution: Tuple[int, int]  # Width, height
    quality_mode: ProcessingMode
    low_memory: bool = False
    crf: Optional[int] = None  # Custom CRF value if specified

class EncoderType(Enum):
    """Available encoder types"""
    NVIDIA_NVENC = "h264_nvenc"
    AMD_AMF = "h264_amf"
    INTEL_QSV = "h264_qsv"
    SOFTWARE_X264 = "libx264"

@dataclass
class ProcessingResult:
    """Results from processing a clip"""
    clip: ClipInfo
    output_path: Path
    duration: float
    frames_processed: int
    success: bool
    error: Optional[str] = None

class VideoProcessor:
    """
    Handles video processing operations for COSM camera output.
    
    This class manages:
    - Segment concatenation
    - Tile extraction and alignment
    - Frame assembly
    - Output encoding
    """
    
    def __init__(self, 
                 output_dir: Path,
                 options: ProcessingOptions,
                 logger: Optional[logging.Logger] = None):
        self.output_dir = output_dir
        self.options = options
        self.logger = logger or logging.getLogger(__name__)
        self._available_encoders = self._detect_encoders()

    def _detect_encoders(self) -> List[EncoderType]:
        """
        Detect available encoders on the system.
        Returns list of encoders in preferred order.
        """
        available = []
        try:
            # Query ffmpeg for encoder list
            result = subprocess.run(
                ["ffmpeg", "-encoders"],
                capture_output=True,
                text=True,
                check=True
            )
            
            # Parse output to detect available encoders
            output = result.stdout.lower()
            
            # Check for hardware encoders first
            if "h264_nvenc" in output:
                available.append(EncoderType.NVIDIA_NVENC)
            if "h264_amf" in output:
                available.append(EncoderType.AMD_AMF)
            if "h264_qsv" in output:
                available.append(EncoderType.INTEL_QSV)
            
            # Software encoder should always be available
            available.append(EncoderType.SOFTWARE_X264)
            
        except subprocess.SubprocessError:
            # If ffmpeg query fails, default to software encoding
            self.logger.warning("Failed to detect encoders, defaulting to software")
            available.append(EncoderType.SOFTWARE_X264)
            
        return available

    def _get_encoder_settings(self, 
                            encoder: EncoderType,
                            thread_count: Optional[int] = None) -> List[str]:
        """
        Get ffmpeg arguments for specified encoder
        
        Args:
            encoder: Encoder to use
            thread_count: Number of threads to use (None for auto)
        """
        # Base quality settings
        crf = self.options.crf or {
            ProcessingMode.QUALITY: 18,
            ProcessingMode.BALANCED: 23,
            ProcessingMode.PERFORMANCE: 28
        }[self.options.quality_mode]
        
        # Start with encoder-specific settings
        if encoder == EncoderType.NVIDIA_NVENC:
            settings = [
                "-c:v", "h264_nvenc",
                "-preset", "p7" if self.options.quality_mode == ProcessingMode.QUALITY else "p4",
                "-qp", str(crf)
            ]
        elif encoder == EncoderType.SOFTWARE_X264:
            settings = [
                "-c:v", "libx264",
                "-preset", "slower" if self.options.quality_mode == ProcessingMode.QUALITY else "medium",
                "-crf", str(crf)
            ]
            
            # Add thread control for software encoding
            if thread_count is not None:
                settings.extend([
                    "-threads", str(thread_count),
                    "-x264-params", f"threads={thread_count}"
                ])
        else:
            # Default settings for other encoders
            settings = ["-c:v", "libx264", "-crf", str(crf)]
        
        return settings

    def _build_filter_complex(self, 
                            crop_overlap: int = 32) -> str:
        """
        Build ffmpeg filter complex for tile processing.
        
        Args:
            crop_overlap: Pixels to crop from overlapping edges
        """
        return (
            # Crop overlapping regions from tiles
            "[0:v:0]crop=iw-{overlap}:ih-{overlap}:0:0[tl];"
            "[0:v:1]crop=iw-{overlap}:ih-{overlap}:{overlap}:0[tr];"
            "[0:v:2]crop=iw-{overlap}:ih-{overlap}:0:{overlap}[bl];"
            "[0:v:3]crop=iw-{overlap}:ih-{overlap}:{overlap}:{overlap}[br];"
            # Stack tiles horizontally
            "[tl][tr]hstack=2[top];"
            "[bl][br]hstack=2[bottom];"
            # Stack rows vertically
            "[top][bottom]vstack=2"
        ).format(overlap=crop_overlap)

    def _create_concat_file(self, segments: List[SegmentInfo]) -> Path:
        """Create temporary concat file for ffmpeg"""
        # Use platform-agnostic temp file creation
        temp_file = Path(tempfile.mktemp(suffix='.txt'))
        
        with open(temp_file, 'w', encoding='utf-8') as f:
            for segment in segments:
                for ts_file in segment.ts_files:
                    # Use forward slashes even on Windows
                    path_str = str(ts_file.absolute()).replace('\\', '/')
                    f.write(f"file '{path_str}'\n")
                    
        return temp_file

    def process_clip(self,
                    clip_result: ClipValidationResult) -> ProcessingResult:
        """
        Process a validated clip.
        
        Args:
            clip_result: Validated clip information
            
        Returns:
            ProcessingResult with status and output details
        """
        try:
            output_path = self.output_dir / f"{clip_result.clip.name}.mp4"
            concat_file = self._create_concat_file(clip_result.segments)
            
            # Determine thread count for software encoding
            if self.options.low_memory:
                import multiprocessing
                total_threads = multiprocessing.cpu_count()
                # Use half threads in low memory mode
                thread_count = max(1, total_threads // 2)
            else:
                thread_count = None
                
            success = False
            error_messages = []
            
            for encoder in self._available_encoders:
                try:
                    # Build base command
                    cmd = [
                        "ffmpeg", "-y",
                        "-f", "concat",
                        "-safe", "0",
                        "-i", str(concat_file),
                        "-filter_complex", self._build_filter_complex()
                    ]
                    
                    # Add encoder settings with thread control for software encoding
                    use_threads = thread_count if (
                        encoder == EncoderType.SOFTWARE_X264 and 
                        self.options.low_memory
                    ) else None
                    
                    cmd.extend(self._get_encoder_settings(encoder, use_threads))
                    
                    # Add output path
                    cmd.append(str(output_path))
                    
                    # Run ffmpeg with proper subprocess configuration for Windows
                    self.logger.info(f"Processing {clip_result.clip.name} with {encoder.value}")
                    subprocess.run(
                        cmd,
                        check=True,
                        capture_output=True,
                        text=True,
                        encoding='utf-8',
                        errors='replace',
                        # Prevent console window on Windows
                        creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
                    )
                    
                    success = True
                    break
                    
                except subprocess.SubprocessError as e:
                    error_messages.append(f"{encoder.value}: {e}")
                    continue
                
            if not success:
                raise RuntimeError(
                    f"All encoders failed: {'; '.join(error_messages)}"
                )
            
            # Calculate processing statistics
            duration = clip_result.clip.duration
            frames = sum(seg.frame_count for seg in clip_result.segments)
            
            return ProcessingResult(
                clip=clip_result.clip,
                output_path=output_path,
                duration=duration,
                frames_processed=frames,
                success=True
            )
            
        except Exception as e:
            self.logger.error(f"Error processing {clip_result.clip.name}: {e}")
            return ProcessingResult(
                clip=clip_result.clip,
                output_path=None,
                duration=0,
                frames_processed=0,
                success=False,
                error=str(e)
            )
            
        finally:
            # Cleanup
            if 'concat_file' in locals():
                concat_file.unlink()

----
Full Path: src/cosmos/__init__.py



----
Full Path: tests/test_processing.py

# tests/test_processing.py
import os
from pathlib import Path
import pytest
import subprocess
from unittest.mock import Mock, patch

from cosmos.processor import (
    ProcessingMode,
    ProcessingOptions,
    EncoderType,
    ProcessingResult,
    VideoProcessor
)
from cosmos.validation import ClipValidationResult, SegmentInfo
from cosmos.manifest import ClipInfo, Position

# Test fixtures
@pytest.fixture
def mock_clip_info():
    """Create a sample ClipInfo object"""
    return ClipInfo(
        name="TEST_CLIP",
        start_epoch=1723559258.022,
        end_epoch=1723559268.022,
        start_pos=Position(0, 0, 25.183),
        end_pos=Position(0, 0, 35.183),
        start_idx=1511,
        end_idx=14273,
        start_time=None  # Not needed for these tests
    )

@pytest.fixture
def mock_segments(tmp_path):
    """Create sample segment information"""
    segments = []
    for i in range(3):
        segment_dir = tmp_path / f"segment_{i}"
        segment_dir.mkdir()
        ts_files = [
            segment_dir / f"chunk_{j}.ts" for j in range(4)
        ]
        for ts_file in ts_files:
            ts_file.touch()
            
        segments.append(SegmentInfo(
            directory=segment_dir,
            start_time=1723559258.022 + i,
            frame_timestamps=[
                1723559258.022 + i + j*0.017 for j in range(4)
            ],
            ts_files=ts_files
        ))
    return segments

@pytest.fixture
def mock_validation_result(mock_clip_info, mock_segments):
    """Create a sample validation result"""
    return ClipValidationResult(
        clip=mock_clip_info,
        segments=mock_segments,
        missing_segments=[],
        issues=[],
        estimated_size=1000000
    )

@pytest.fixture
def processor(tmp_path):
    """Create a VideoProcessor instance with test configuration"""
    options = ProcessingOptions(
        output_resolution=(3840, 2160),
        quality_mode=ProcessingMode.BALANCED
    )
    return VideoProcessor(tmp_path / "output", options)

class TestVideoProcessor:
    def test_encoder_detection(self, processor):
        """Test encoder detection and ordering"""
        # Mock ffmpeg -encoders output
        ffmpeg_output = """
        Encoders:
         V..... libx264        x264 H.264 / AVC / MPEG-4 AVC
         V..... h264_nvenc     NVIDIA NVENC H.264 encoder
        """
        
        with patch('subprocess.run') as mock_run:
            mock_run.return_value.stdout = ffmpeg_output
            mock_run.return_value.returncode = 0
            
            encoders = processor._detect_encoders()
            
            assert EncoderType.NVIDIA_NVENC in encoders
            assert EncoderType.SOFTWARE_X264 in encoders
            assert encoders.index(EncoderType.NVIDIA_NVENC) < encoders.index(EncoderType.SOFTWARE_X264)

    def test_encoder_detection_fallback(self, processor):
        """Test fallback to software encoding when detection fails"""
        with patch('subprocess.run') as mock_run:
            mock_run.side_effect = subprocess.SubprocessError()
            
            encoders = processor._detect_encoders()
            
            assert len(encoders) == 1
            assert encoders[0] == EncoderType.SOFTWARE_X264

    def test_filter_complex_generation(self, processor):
        """Test FFmpeg filter complex string generation"""
        filter_complex = processor._build_filter_complex(crop_overlap=32)
        
        assert "[0:v:0]crop" in filter_complex
        assert "hstack=2" in filter_complex
        assert "vstack=2" in filter_complex

    def test_encoder_settings_quality_modes(self, processor):
        """Test encoder settings for different quality modes"""
        # Test QUALITY mode
        options = ProcessingOptions(
            output_resolution=(3840, 2160),
            quality_mode=ProcessingMode.QUALITY
        )
        processor.options = options
        settings = processor._get_encoder_settings(EncoderType.SOFTWARE_X264)
        assert "slower" in settings
        assert "-crf" in settings
        assert "18" in settings  # Highest quality CRF
        
        # Test PERFORMANCE mode
        options.quality_mode = ProcessingMode.PERFORMANCE
        settings = processor._get_encoder_settings(EncoderType.SOFTWARE_X264)
        assert "medium" in settings
        assert "-crf" in settings
        assert "28" in settings  # Lower quality CRF

    def test_thread_control(self, processor):
        """Test thread control for different processing modes"""
        import multiprocessing
        total_threads = multiprocessing.cpu_count()
        
        # Test LOW_MEMORY mode
        options = ProcessingOptions(
            output_resolution=(3840, 2160),
            quality_mode=ProcessingMode.LOW_MEMORY
        )
        processor.options = options
        settings = processor._get_encoder_settings(
            EncoderType.SOFTWARE_X264,
            thread_count=total_threads // 2
        )
        assert "-threads" in settings
        assert str(total_threads // 2) in settings
        
        # Test MINIMAL mode
        options.quality_mode = ProcessingMode.MINIMAL
        settings = processor._get_encoder_settings(
            EncoderType.SOFTWARE_X264,
            thread_count=1
        )
        assert "-threads" in settings
        assert "1" in settings

    @pytest.mark.parametrize("platform", ["win32", "linux", "darwin"])
    def test_cross_platform_paths(self, processor, mock_validation_result, platform):
        """Test path handling across different platforms"""
        with patch('os.name', platform):
            concat_file = processor._create_concat_file(mock_validation_result.segments)
            
            # Check concat file contents
            with open(concat_file) as f:
                content = f.read()
                
            # Verify forward slashes are used regardless of platform
            assert '\\' not in content
            assert all(line.startswith("file '") for line in content.splitlines() if line)

    @patch('subprocess.run')
    def test_process_clip(self, mock_run, processor, mock_validation_result):
        """Test complete clip processing workflow"""
        # Mock successful ffmpeg execution
        mock_run.return_value.returncode = 0
        
        result = processor.process_clip(mock_validation_result)
        
        assert result.success
        assert result.frames_processed > 0
        assert result.output_path.name == f"{mock_validation_result.clip.name}.mp4"
        
        # Verify ffmpeg was called with expected arguments
        assert mock_run.called
        cmd_args = mock_run.call_args[0][0]
        assert "ffmpeg" in cmd_args
        assert "-filter_complex" in cmd_args
        
    @patch('subprocess.run')
    def test_process_clip_error_handling(self, mock_run, processor, mock_validation_result):
        """Test error handling during processing"""
        # Mock ffmpeg failure
        mock_run.side_effect = subprocess.CalledProcessError(1, "ffmpeg")
        
        result = processor.process_clip(mock_validation_result)
        
        assert not result.success
        assert result.error is not None

    def test_windows_specific_flags(self, processor):
        """Test Windows-specific subprocess flags"""
        with patch('os.name', 'nt'):
            # Mock the processing to check command construction
            with patch('subprocess.run') as mock_run:
                mock_run.return_value.returncode = 0
                processor.process_clip(mock_validation_result)
                
                # Verify CREATE_NO_WINDOW flag was used
                assert 'creationflags' in mock_run.call_args[1]
                assert mock_run.call_args[1]['creationflags'] == subprocess.CREATE_NO_WINDOW

----
Full Path: tests/test_integration.py

# File: tests/test_integration.py

import subprocess
import sys

def test_self_test_integration():
    input_dir = "/datasets/dataZoo/clients/ladybird_data/LADYBIRD/failed_copy"
    output_dir = "/datasets/dataZoo/clients/ladybird_data/LADYBIRD/cosmos_out"

    cmd = [
        sys.executable, "cosmos.py",
        "--self-test",
        "--input-dir", input_dir,
        "--output-dir", output_dir
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0, f"Self-test failed with non-zero exit code: {result.returncode}\nSTDERR: {result.stderr}"
    assert "Self-test passed. System ready." in result.stdout, f"Expected success message not in output.\nSTDOUT: {result.stdout}"


----
Full Path: tests/__init__.py



----
Full Path: tests/test_validation.py

# tests/test_validation.py
import json
from pathlib import Path
import pytest
import shutil
import subprocess
from datetime import datetime

from cosmos.validation import (
    InputValidator,
    ValidationLevel,
    ValidationIssue,
    SegmentInfo,
    ClipValidationResult,
    ValidationResult
)
from cosmos.manifest import Position, ClipInfo, ManifestParser

# Test fixtures
@pytest.fixture
def mock_input_dir(tmp_path):
    """Create a mock input directory structure with test data"""
    input_dir = tmp_path / "input"
    input_dir.mkdir()
    
    # Create a simple directory structure
    # 0H/0M/25S - 0H/0M/27S
    base = input_dir / "0H" / "0M"
    base.mkdir(parents=True)
    
    # Create segment directories with meta.json files
    for second in range(25, 28):
        segment_dir = base / f"{second}S"
        segment_dir.mkdir()
        
        # Create meta.json
        meta = {
            "Time": {
                "x0": 1723559258.0 + second,
                "xi-x0": [0.0, 0.017, 0.033, 0.050]
            }
        }
        with open(segment_dir / "meta.json", "w") as f:
            json.dump(meta, f)
            
        # Create dummy .ts files
        for i in range(4):
            (segment_dir / f"chunk_{i}.ts").touch()
    
    return input_dir

@pytest.fixture
def mock_output_dir(tmp_path):
    """Create a mock output directory"""
    output_dir = tmp_path / "output"
    output_dir.mkdir()
    return output_dir

@pytest.fixture
def sample_manifest(tmp_path):
    """Create a test manifest file"""
    manifest_content = """
    <Clip_Manifest NumDirs="498">
      <_1 Name="CLIP1" InIdx="1511" OutIdx="14273" Locked="True" 
          InStr="07:27:38.022 08/13/2024" Epoch="1723559258.022" 
          Pos="0H/0M/25.1833333333333S/" />
    </Clip_Manifest>
    """
    manifest_path = tmp_path / "test_manifest.xml"
    manifest_path.write_text(manifest_content)
    return manifest_path

@pytest.fixture
def validator(mock_input_dir, mock_output_dir, sample_manifest):
    """Create an InputValidator instance with test data"""
    parser = ManifestParser(sample_manifest)
    return InputValidator(mock_input_dir, mock_output_dir, parser)

class TestSegmentInfo:
    @pytest.fixture
    def sample_segment(self, tmp_path):
        """Create a sample SegmentInfo object"""
        return SegmentInfo(
            directory=tmp_path,
            start_time=1723559258.022,
            frame_timestamps=[
                1723559258.022,
                1723559258.039,
                1723559258.056
            ],
            ts_files=[
                tmp_path / "1.ts",
                tmp_path / "2.ts",
                tmp_path / "3.ts"
            ]
        )
    
    def test_end_time(self, sample_segment):
        assert sample_segment.end_time == 1723559258.056
        
    def test_frame_count(self, sample_segment):
        assert sample_segment.frame_count == 3
        
    def test_has_all_files(self, sample_segment):
        assert sample_segment.has_all_files is True

class TestInputValidator:
    def test_validate_system_ffmpeg_missing(self, validator, monkeypatch):
        """Test system validation when ffmpeg is not available"""
        def mock_run(*args, **kwargs):
            raise FileNotFoundError()
            
        monkeypatch.setattr(subprocess, "run", mock_run)
        issues = validator.validate_system()
        
        assert any(
            issue.level == ValidationLevel.ERROR and "FFmpeg" in issue.message
            for issue in issues
        )
    
    def test_validate_segment_valid(self, validator, mock_input_dir):
        """Test validation of a valid segment directory"""
        segment_dir = mock_input_dir / "0H" / "0M" / "25S"
        segment_info = validator.validate_segment(segment_dir)
        
        assert segment_info is not None
        assert segment_info.frame_count == 4
        assert len(segment_info.ts_files) == 4
        
    def test_validate_segment_invalid_meta(self, mock_input_dir):
        """Test validation with invalid meta.json"""
        segment_dir = mock_input_dir / "0H" / "0M" / "25S"
        
        # Corrupt meta.json
        with open(segment_dir / "meta.json", "w") as f:
            f.write("invalid json")
            
        validator = InputValidator(
            mock_input_dir,
            mock_input_dir / "output",
            ManifestParser(mock_input_dir / "manifest.xml")
        )
        
        segment_info = validator.validate_segment(segment_dir)
        assert segment_info is None
    
    def test_validate_clip(self, validator):
        """Test validation of a complete clip"""
        clip = validator.manifest_parser.get_clips()[0]
        result = validator.validate_clip(clip)
        
        assert isinstance(result, ClipValidationResult)
        assert len(result.segments) > 0
        assert result.is_valid
        
    def test_validate_clip_missing_segments(self, validator, mock_input_dir):
        """Test validation with missing segments"""
        # Remove a segment directory
        shutil.rmtree(mock_input_dir / "0H" / "0M" / "26S")
        
        clip = validator.manifest_parser.get_clips()[0]
        result = validator.validate_clip(clip)
        
        assert not result.is_valid
        assert len(result.missing_segments) > 0
        
    def test_validate_all(self, validator):
        """Test complete validation process"""
        result = validator.validate_all()
        
        assert isinstance(result, ValidationResult)
        assert result.can_proceed
        assert result.available_space > 0
        assert result.total_size_estimate > 0
        
    def test_validation_with_no_space(self, validator, monkeypatch):
        """Test validation when disk space is insufficient"""
        def mock_disk_usage(*args):
            return type('Usage', (), {'free': 0})()
            
        monkeypatch.setattr(shutil, "disk_usage", mock_disk_usage)
        
        result = validator.validate_all()
        assert not result.can_proceed

def test_validation_issue_creation():
    """Test ValidationIssue creation and attributes"""
    issue = ValidationIssue(
        level=ValidationLevel.ERROR,
        message="Test error",
        context="Test context",
        help_text="Test help"
    )
    
    assert issue.level == ValidationLevel.ERROR
    assert issue.message == "Test error"
    assert issue.context == "Test context"
    assert issue.help_text == "Test help"

----
Full Path: tests/test_manifest.py

# tests/test_manifest.py
from pathlib import Path
import pytest
from datetime import datetime
from cosmos.manifest import (
    Position, 
    ClipInfo, 
    ClipStatus, 
    ManifestParser, 
    find_manifest
)

# Test data
SAMPLE_MANIFEST = """
<Clip_Manifest NumDirs="498">
  <_1 Name="CLIP2" In="1.6261465427355111E-307" InIdx="228" Out="1.6261466707242047E-307" OutIdx="4110" Locked="True" InStr="07:27:16.618 08/13/2024" Epoch="1723559236.618" Pos="0H/0M/3.8S/" />
  <_2 Name="CLIP1" In="1.6261465850368715E-307" InIdx="1511" Out="1.6261470057932999E-307" OutIdx="14273" Locked="True" InStr="07:27:38.022 08/13/2024" Epoch="1723559258.0219998" Pos="0H/0M/25.1833333333333S/" />
</Clip_Manifest>
"""

@pytest.fixture
def sample_manifest(tmp_path):
    """Create a temporary manifest file for testing"""
    manifest_path = tmp_path / "test_manifest.xml"
    manifest_path.write_text(SAMPLE_MANIFEST)
    return manifest_path

class TestPosition:
    def test_from_valid_string(self):
        pos = Position.from_string("0H/0M/3.8S/")
        assert pos.hour == 0
        assert pos.minute == 0
        assert pytest.approx(pos.second, 0.001) == 3.8
        
    def test_from_invalid_string(self):
        with pytest.raises(ValueError):
            Position.from_string("invalid")
            
    def test_to_seconds(self):
        pos = Position(hour=1, minute=30, second=15.5)
        assert pytest.approx(pos.to_seconds(), 0.001) == 5415.5
        
    def test_to_string(self):
        pos = Position(hour=0, minute=0, second=3.8)
        assert pos.to_string() == "0H/0M/3.8S"

class TestClipInfo:
    @pytest.fixture
    def sample_clip(self):
        return ClipInfo(
            name="CLIP1",
            start_epoch=1723559258.022,
            end_epoch=1723559268.022,  # 10 seconds duration
            start_pos=Position(0, 0, 25.183),
            end_pos=Position(0, 0, 35.183),
            start_idx=1511,
            end_idx=14273,
            start_time=datetime(2024, 8, 13, 7, 27, 38, 22000)
        )
    
    def test_duration(self, sample_clip):
        assert pytest.approx(sample_clip.duration, 0.001) == 10.0
        
    def test_frame_count(self, sample_clip):
        assert sample_clip.frame_count == 12762

class TestManifestParser:
    def test_parser_initialization(self, sample_manifest):
        parser = ManifestParser(sample_manifest)
        assert len(parser.get_clips()) == 2
        
    def test_nonexistent_manifest(self):
        with pytest.raises(FileNotFoundError):
            ManifestParser(Path("nonexistent.xml"))
            
    def test_get_clip(self, sample_manifest):
        parser = ManifestParser(sample_manifest)
        clip = parser.get_clip("CLIP1")
        assert clip is not None
        assert clip.name == "CLIP1"
        assert pytest.approx(clip.start_epoch, 0.001) == 1723559258.022
        
    def test_clips_temporal_order(self, sample_manifest):
        parser = ManifestParser(sample_manifest)
        clips = parser.get_clips()
        assert len(clips) == 2
        assert clips[0].name == "CLIP2"  # Earlier timestamp
        assert clips[1].name == "CLIP1"
        
    def test_find_clip_for_timestamp(self, sample_manifest):
        parser = ManifestParser(sample_manifest)
        clip = parser.find_clip_for_timestamp(1723559236.618)
        assert clip is not None
        assert clip.name == "CLIP2"
        
    def test_update_clip_status(self, sample_manifest):
        parser = ManifestParser(sample_manifest)
        parser.update_clip_status("CLIP1", ClipStatus.COMPLETE)
        clip = parser.get_clip("CLIP1")
        assert clip.status == ClipStatus.COMPLETE

def test_find_manifest(tmp_path):
    # Test single manifest
    manifest_path = tmp_path / "test.xml"
    manifest_path.write_text(SAMPLE_MANIFEST)
    assert find_manifest(tmp_path) == manifest_path
    
    # Test no manifest
    empty_dir = tmp_path / "empty"
    empty_dir.mkdir()
    assert find_manifest(empty_dir) is None
    
    # Test multiple manifests
    another_manifest = tmp_path / "another.xml"
    another_manifest.write_text(SAMPLE_MANIFEST)
    with pytest.raises(ValueError):
        find_manifest(tmp_path)

